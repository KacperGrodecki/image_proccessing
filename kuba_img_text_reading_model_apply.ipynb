{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kuba_img_text_reading_model_apply.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrKEZlBpNjaeHack1Ypnwl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KacperGrodecki/image_proccessing/blob/main/kuba_img_text_reading_model_apply.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJjlrbzGKZi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260c67a5-a6bc-4c49-978f-726c3fa97b53"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaccDd3JEho8",
        "outputId": "7e83f8dd-1ff8-4034-a82c-73b0b17cffff"
      },
      "source": [
        "!apt-get install poppler-utils \n",
        "!apt-get install tesseract-ocr-pol\n",
        "!apt-get install libleptonica-dev \n",
        "!apt-get install tesseract-ocr\n",
        "!apt-get install tesseract-ocr-dev\n",
        "!apt-get install libtesseract-dev"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 154 kB of archives.\n",
            "After this operation, 613 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 poppler-utils amd64 0.62.0-2ubuntu2.12 [154 kB]\n",
            "Fetched 154 kB in 1s (293 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 155062 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.62.0-2ubuntu2.12_amd64.deb ...\n",
            "Unpacking poppler-utils (0.62.0-2ubuntu2.12) ...\n",
            "Setting up poppler-utils (0.62.0-2ubuntu2.12) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd tesseract-ocr-pol\n",
            "0 upgraded, 4 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 6,404 kB of archives.\n",
            "After this operation, 20.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-pol all 4.00~git24-0e00fe6-1.2 [1,609 kB]\n",
            "Fetched 6,404 kB in 1s (5,745 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 155090 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Selecting previously unselected package tesseract-ocr-pol.\n",
            "Preparing to unpack .../tesseract-ocr-pol_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-pol (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-pol (4.00~git24-0e00fe6-1.2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libleptonica-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,308 kB of archives.\n",
            "After this operation, 5,966 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libleptonica-dev amd64 1.75.3-3 [1,308 kB]\n",
            "Fetched 1,308 kB in 1s (1,576 kB/s)\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "(Reading database ... 155141 files and directories currently installed.)\n",
            "Preparing to unpack .../libleptonica-dev_1.75.3-3_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.75.3-3) ...\n",
            "Setting up libleptonica-dev (1.75.3-3) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "tesseract-ocr set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Package tesseract-ocr-dev is not available, but is referred to by another package.\n",
            "This may mean that the package is missing, has been obsoleted, or\n",
            "is only available from another source\n",
            "However the following packages replace it:\n",
            "  libtesseract-dev\n",
            "\n",
            "E: Package 'tesseract-ocr-dev' has no installation candidate\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libtesseract-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,447 kB of archives.\n",
            "After this operation, 7,824 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtesseract-dev amd64 4.00~git2288-10f4998a-2 [1,447 kB]\n",
            "Fetched 1,447 kB in 1s (1,785 kB/s)\n",
            "Selecting previously unselected package libtesseract-dev.\n",
            "(Reading database ... 155184 files and directories currently installed.)\n",
            "Preparing to unpack .../libtesseract-dev_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking libtesseract-dev (4.00~git2288-10f4998a-2) ...\n",
            "Setting up libtesseract-dev (4.00~git2288-10f4998a-2) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6FImYcoRS3q",
        "outputId": "1c134c08-b749-499d-f5de-3982544a435e"
      },
      "source": [
        "pip install pytesseract "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.8.tar.gz (14 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14072 sha256=70a15750e7c089b9a6351e3e4fff590488a02a8e34e202badd5861c1bf620de8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/89/b9/3f11250225d0f90e5454fcc30fd1b7208db226850715aa9ace\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBEZ4rsZX7GZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6974362-12ae-4320-8dd1-e9606c2ee7c1"
      },
      "source": [
        "pip install autocorrect"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.5.0.tar.gz (622 kB)\n",
            "\u001b[K     |████████████████████████████████| 622 kB 5.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.5.0-py3-none-any.whl size=621851 sha256=40bba9795d17c2fc8272e8eae7b02e645d668ccb1a7bd097b1b849394bfcaad5\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/8e/bd/f6fd900a056a031bf710a00bca338d86f43b83f0c25ab5242f\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wUfYi8wWZLT"
      },
      "source": [
        "import pytesseract\n",
        "#pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image,ImageTk\n",
        "from pytesseract import image_to_string\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt      \n",
        "from skimage import io, color, morphology\n",
        "import pickle\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import gc\n",
        "import sys\n",
        "import pickle"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT8h2H13J1TL"
      },
      "source": [
        "#statistics\n",
        "def average_word_length(text):\n",
        "    if isinstance(text, str):\n",
        "        text=re.sub(r'W+', '',text)\n",
        "        if len(text.strip())>0:\n",
        "            total_length = len(text)-text.count(' ')\n",
        "            num_words = len(text.split())\n",
        "            return total_length/num_words\n",
        "        else:\n",
        "            return 0\n",
        "    elif text==np.nan:\n",
        "        return 0\n",
        "    else:\n",
        "        average_word_length(str(text))\n",
        "        \n",
        "def std(text):\n",
        "    if isinstance(text, str):\n",
        "        text=re.sub(r'W+', '',text)\n",
        "        if len(text.strip())>0:\n",
        "            total_length = len(text)-text.count(' ')\n",
        "            num_words = len(text.split())\n",
        "            avg=total_length/num_words\n",
        "            words=text.split()\n",
        "            out=0\n",
        "            for word in words:\n",
        "                out+=(len(word)-avg)**2 \n",
        "            return (out/num_words)**0.5\n",
        "        else:\n",
        "            return 0\n",
        "    elif text==np.nan:\n",
        "        return 0\n",
        "    else:\n",
        "        std(str(text))\n",
        "        \n",
        "def longest(text):\n",
        "    if isinstance(text, str):\n",
        "        if len(text.strip())>0:\n",
        "            words=text.split()\n",
        "            out=0\n",
        "            for word in words:\n",
        "                if len(word)>out:\n",
        "                    out=len(word)\n",
        "            return out\n",
        "        else:\n",
        "            return 0\n",
        "    elif text==np.nan:\n",
        "        return 0\n",
        "    else:\n",
        "        std(str(text))\n",
        "\n",
        "def char_type_counter(text):\n",
        "    #print(text)\n",
        "    if isinstance(text, str):\n",
        "        dig,alpha=0,0\n",
        "        for char in text.strip():\n",
        "            if char.isdigit():\n",
        "                dig+=1\n",
        "            elif char.isalpha():\n",
        "                alpha+=1\n",
        "        if dig+alpha==0:\n",
        "            return 0\n",
        "        else:\n",
        "            return alpha/(dig+alpha)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def unique_chars_set(s):\n",
        "    if type(s) ==str:\n",
        "      return  (len(s)-len(set(s)))/len(s)\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGIh2lJJWtAN"
      },
      "source": [
        "class Run():\n",
        "\n",
        "    def __init__(self):\n",
        "        #print('start')\n",
        "        self.countter = 0\n",
        "        self.countter1 = 0\n",
        "        self.labels = []\n",
        "        self.xywh = []\n",
        "        self.xywh1 = []\n",
        "        self.path = 'drive/MyDrive/kuba/'\n",
        "        self.files = [f for f in listdir(self.path) if isfile(join(self.path, f))]\n",
        "        self.files.sort()\n",
        "        self.contours = 0\n",
        "\n",
        "    def setNumber(self,i):\n",
        "        self.file_nr = i\n",
        "\n",
        "    def openFile(self):\n",
        "        self.file = self.path + self.files[self.file_nr]\n",
        "        return self.file\n",
        "\n",
        "    def findContour(self,ImageProcessing):\n",
        "        fig_prepared = ImageProcessing.figPrepare(self.file)\n",
        "        self.contours, self.xywh = ImageProcessing.find_contours(fig_prepared)\n",
        "        return self.contours\n",
        "\n",
        "    def readText(self, cropped_board):\n",
        "        crop = Image.fromarray(cropped_board)\n",
        "        try:\n",
        "            let_crop = image_to_string(cropped_board, lang='pol', config='--psm 7 --oem 3')\n",
        "        except:\n",
        "            let_crop = ''\n",
        "        try:\n",
        "            div_crop = image_to_string(cropped_board, lang='pol', config='--psm 6 --oem 3')\n",
        "        except:\n",
        "            let_crop = ''\n",
        "        if re.search('[a-zA-Z]', let_crop) or re.search('[a-zA-Z]', div_crop):\n",
        "            dig_crop = image_to_string(cropped_board, lang='pol', config='--psm 7 --oem 3 -c tessedit_char_whitelist=0123456789')  # r'--oem 3 --psm 3 outputbase digits'\n",
        "####################################################wyswietlanie tekstu\n",
        "            #print(let_crop, div_crop)\n",
        "########################################################\n",
        "            if self.modelCheck(let_crop)==1:\n",
        "              print('yes ',let_crop)\n",
        "            else:\n",
        "              print('no ',let_crop)\n",
        "            if self.modelCheck(div_crop)==1:\n",
        "              print('yes ',div_crop)\n",
        "            else:\n",
        "              print('no ',div_crop)\n",
        "            return let_crop, div_crop\n",
        "        else:\n",
        "            return '',''\n",
        "    def modelCheck(self,x):\n",
        "      averages=average_word_length(x)\n",
        "      stds=std(x)\n",
        "      long1=longest(x)\n",
        "      char_type_count=char_type_counter(x)\n",
        "      unique_chars=unique_chars_set(x)\n",
        "      errors=int('ERROR' in x)\n",
        "      x=np.array([averages,stds,long1,char_type_count,unique_chars,errors])\n",
        "      filename='drive/MyDrive/kuba/model.joblib'\n",
        "      with open(filename, 'rb') as file:  \n",
        "       model = pickle.load(file)\n",
        "      return model.predict(np.transpose(x.reshape(-1,1)))[0]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHn3W6gUWvQp"
      },
      "source": [
        "class ImageProcessing:\n",
        "\n",
        "    def figPrepare(self, file):\n",
        "        rgb_image = cv2.imread(file)\n",
        "\n",
        "        gray_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2GRAY)\n",
        "        lower_blue=np.array([0])\n",
        "        upper_blue=np.array([120])\n",
        "        mask=cv2.inRange(gray_image,lower_blue,upper_blue)\n",
        "\n",
        "        res=cv2.bitwise_and(gray_image,gray_image,mask=mask)\n",
        "        res[mask==0]=[255]\n",
        "        board=int(res.shape[1]*0.01)\n",
        "        res[:,:board]=255\n",
        "        res[:,-board:]=255\n",
        "\n",
        "\n",
        "        return res#gray_image_copy\n",
        "\n",
        "    def countrurs(self, gray, ythresh):\n",
        "        thresh = 255 - gray\n",
        "        # use morphology erode to blur horizontally\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (151, 3))\n",
        "        morph = cv2.morphologyEx(thresh, cv2.MORPH_DILATE, kernel)\n",
        "\n",
        "        # use morphology open to remove thin lines from dotted lines\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 17))\n",
        "        morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel)\n",
        "        cntrs = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        cntrs = cntrs[0] if len(cntrs) == 2 else cntrs[1]\n",
        "\n",
        "        # find the topmost box\n",
        "\n",
        "        for c in cntrs:\n",
        "            box = cv2.boundingRect(c)\n",
        "            x, y, w, h = box\n",
        "            if y < ythresh:\n",
        "                topbox = box\n",
        "                ythresh = y\n",
        "        \n",
        "        return cntrs[::-1], topbox\n",
        "\n",
        "    # loading contours\n",
        "    def image_correction(self,gray_image):\n",
        "        unique, counts = np.unique(gray_image, return_counts=True)\n",
        "        hist_max=np.argmax(counts[120:180])+120\n",
        "        hist_max_all=np.argmax(counts)\n",
        "        \n",
        "        kernelSizes = (11, 11)\n",
        "        gray_image_blurred = cv2.blur(gray_image,kernelSizes)\n",
        "        gray_image_copy=gray_image.copy()\n",
        "        gray_image_copy[(gray_image<hist_max+20)&(gray_image>hist_max-20)]=hist_max_all+10\n",
        "\n",
        "        return gray_image_copy\n",
        "\n",
        "    def find_contours(self, file):\n",
        "        image = file\n",
        "  \n",
        "        result=self.image_correction(image)####################test-podmieniona linijka wyzej#########\n",
        "        ythresh = 1000\n",
        "        cntrs, topbox = self.countrurs(image, ythresh)\n",
        "        i = 0\n",
        "        images = []\n",
        "        xywh = []\n",
        "        for c in cntrs:\n",
        "            box = cv2.boundingRect(c)\n",
        "            if box != topbox:\n",
        "                i = i + 1\n",
        "                x, y, w, h = box\n",
        "\n",
        "                xywh.append([x, y, w, h])\n",
        "\n",
        "                cv2.rectangle(result, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
        "                cropped = image[y:y + h, x:x + w]\n",
        "\n",
        "                # mask,mask1 = self.mask_from_cropped(cropped)\n",
        "                board = 50\n",
        "                cropped_board = cv2.copyMakeBorder(cropped, board, board, board, board, cv2.BORDER_CONSTANT,\n",
        "                                                   value=[255, 255, 255])\n",
        "\n",
        "                images.append(cropped_board)\n",
        "        return images, xywh\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KLJ0LxxfWUU4",
        "outputId": "c2a133c8-a806-4e5b-f2ea-f221944fa6a0"
      },
      "source": [
        "imageProcessing=ImageProcessing()\n",
        "run=Run()\n",
        "text_df=pd.DataFrame(np.array([' ',' ']))\n",
        "text=[]\n",
        "for i in range(0,10):\n",
        "    print('-------------------------',i,'--------------------------')\n",
        "    \n",
        "    #ImageProcessing\n",
        "    run.setNumber(i)\n",
        "    try:\n",
        "      file=run.openFile()\n",
        "    except:\n",
        "      break\n",
        "    text.append(file)\n",
        "    print(file)\n",
        "    if \"concat\" in file:\n",
        "      continue\n",
        "    contours=run.findContour(imageProcessing)\n",
        "    #print(len(contours))\n",
        "    j=0\n",
        "    for contour in contours:\n",
        "        line,div=run.readText(contour)\n",
        "        text.append(line)\n",
        "        if div!=line:\n",
        "          text.append(div)\n",
        "        j+=1\n",
        "    #print(np.array(text).flatten())\n",
        "    #text_df.append(pd.DataFrame(np.array(text).flatten()))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------- 0 --------------------------\n",
            "drive/MyDrive/kuba/concat.csv\n",
            "------------------------- 1 --------------------------\n",
            "drive/MyDrive/kuba/concat.gsheet\n",
            "------------------------- 2 --------------------------\n",
            "drive/MyDrive/kuba/concat1.csv\n",
            "------------------------- 3 --------------------------\n",
            "drive/MyDrive/kuba/concat1.gsheet\n",
            "------------------------- 4 --------------------------\n",
            "drive/MyDrive/kuba/concat1.xlsx\n",
            "------------------------- 5 --------------------------\n",
            "drive/MyDrive/kuba/fig1.jpg\n",
            "no  \f\n",
            "yes  Własność\n",
            "archiwum\n",
            "Aktotwórca\n",
            "Tytuł teczki\n",
            "Daty skrajne\n",
            "jednostki\n",
            "archiwalnej\n",
            "Stara sygnatura\n",
            "Sygnatura\n",
            "archiwalna\n",
            "\f\n",
            "yes  IPN BU 0 639/223\n",
            "\f\n",
            "yes  IPN BU 0 639/223\n",
            "\f\n",
            "yes  KARTA INFORMACYJNA\n",
            "\f\n",
            "yes  KARTA INFORMACYJNA\n",
            "\f\n",
            "no  r.\n",
            "\f\n",
            "no  r.\n",
            "\f\n",
            "yes  Własność\n",
            "\f\n",
            "yes  Własność\n",
            "\f\n",
            "yes  Instytut Pamięci Narodowej w Warszawie\n",
            "\f\n",
            "yes  Instytut Pamięci Narodowej w Warszawie\n",
            "\f\n",
            "yes  archiwum\n",
            "\f\n",
            "yes  archiwum\n",
            "\f\n",
            "yes  Aktotwórca\n",
            "\f\n",
            "yes  Aktotwórca\n",
            "\f\n",
            "yes  MSW\n",
            "\f\n",
            "yes  MSW\n",
            "\f\n",
            "yes  Tytuł teczki\n",
            "\f\n",
            "yes  Tytuł teczki\n",
            "\f\n",
            "yes  PAX- materiały dotyczące działalności zrzeszenia\n",
            "\f\n",
            "yes  PAX- materiały dotyczące działalności zrzeszenia\n",
            "\f\n",
            "yes  Daty skrajne\n",
            "\f\n",
            "yes  Daty skrajne\n",
            "\f\n",
            "yes  jednostki\n",
            "\f\n",
            "yes  jednostki\n",
            "\f\n",
            "yes  archiwalnej\n",
            "\f\n",
            "yes  archiwalnej\n",
            "\f\n",
            "yes  IPN BU 0639/223\n",
            "\f\n",
            "yes  IPN BU 0639/223\n",
            "\f\n",
            "yes  Sygnatura\n",
            "\f\n",
            "yes  Sygnatura\n",
            "\f\n",
            "yes  archiwalna\n",
            "\f\n",
            "yes  archiwalna\n",
            "\f\n",
            "yes  1 z 348\n",
            "\f\n",
            "yes  1 z 348\n",
            "\f\n",
            "------------------------- 6 --------------------------\n",
            "drive/MyDrive/kuba/fig10.jpg\n",
            "no  A\n",
            "\f\n",
            "no  A\n",
            "\f\n",
            "no  b r\n",
            "\f\n",
            "no  b r\n",
            "\f\n",
            "yes  rad\n",
            "\f\n",
            "yes  =\n",
            ".\n",
            "\f\n",
            "yes  Za ałą EZEHO 639/223\n",
            "\f\n",
            "yes  Za ałą EZEHO 639/223\n",
            "\f\n",
            "yes  STRUKTURA I WYKONANIE BUDŻETÓW\n",
            "\f\n",
            "yes  STRUKTURA I WYKONANIE BUDŻETÓW\n",
            "\f\n",
            "no  e «am GW UR WER WM UTW WW WW «a Rz WUW WWW W\n",
            "\f\n",
            "no  \f\n",
            "yes  KATOLICKICH ORGANIZACJI SPOŁECZNYCH :\n",
            "\f\n",
            "yes  KATOLICKICH ORGANIZACJI SPOŁECZNYCH :\n",
            "\f\n",
            "no  ip suk w w w W w A Ww w w W wi ww w w w i ww w w W w w w W m wa m CZY wa w w A w W ww <a a WA w A a W m\n",
            "\f\n",
            "no  \f\n",
            "yes  \"PAX\", ChSS, KIK za rok 1971\n",
            "\f\n",
            "yes  \"PAX\", ChSS, KIK za rok 1971\n",
            "\f\n",
            "yes  w «m cRRTRĘUWRCRKKKRUWWWWW WKKW WUW ZUW TY MM eu uwa WWW iWM w dY <R uwR\n",
            "\f\n",
            "yes  w «m cRRTRĘUWRCRKKKRUWWWWW WKKW WUW ZUW TY MM eu uwa WWW iWM w dY <R uwR\n",
            "\f\n",
            "yes  STOWARZYSZENIE \"PAX\"\n",
            "\f\n",
            "yes  STOWARZYSZENIE \"PAX\"\n",
            "\f\n",
            "no  m wake CR=M RT RUR WW TW WWRWWW\n",
            "\f\n",
            "no  \f\n",
            "yes  Realizacja budżetu. za rok 1971:\n",
            "\f\n",
            "yes  Realizacja budżetu. za rok 1971:\n",
            "\f\n",
            "yes  = 36, 720, 000,7 GŁ.\n",
            "\f\n",
            "yes  = 36, 720, 000,7 GŁ.\n",
            "\f\n",
            "yes  - działalność statutowa\n",
            "\f\n",
            "yes  - działalność statutowa\n",
            "\f\n",
            "yes  - pokrycie straty prasy i wydawnictw - 28.680.000.\" zł.\n",
            "\f\n",
            "yes  - pokrycie straty prasy i wydawnictw - 28.680.000.\" zł.\n",
            "\f\n",
            "no  a „| a a m m a w w a m a A wę m mw\n",
            "\f\n",
            "no  a „| a a m m a w w a m a A wę m mw\n",
            "\f\n",
            "yes  __..razem;_ 65.400.000, - zł.\n",
            "\f\n",
            "yes  — mem. 65.400.000, zł.\n",
            "\f\n",
            "yes  Struktura budżetu :\n",
            "\f\n",
            "yes  Struktura budżetu :\n",
            "\f\n",
            "no  «mw m mm ma mw w a m m\n",
            "\f\n",
            "no  \f\n",
            "yes  1. Płace / osobowy fundusz płac,\n",
            "\f\n",
            "yes  1. Płace / osobowy fundusz płac,\n",
            "\f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-0072cf4913b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcontour\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontours\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-0b740117fb66>\u001b[0m in \u001b[0;36mreadText\u001b[0;34m(self, cropped_board)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m#print(let_crop, div_crop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelCheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlet_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yes '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlet_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-0b740117fb66>\u001b[0m in \u001b[0;36mmodelCheck\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mlong1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlongest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0mchar_type_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchar_type_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m       \u001b[0munique_chars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_chars_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m       \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ERROR'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maverages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlong1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchar_type_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique_chars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-0edca5576a4c>\u001b[0m in \u001b[0;36munique_chars_set\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munique_chars_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m       \u001b[0;32mreturn\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7_gnLZJnifw",
        "outputId": "8e90036f-8e71-4ab0-8250-3118ff931594"
      },
      "source": [
        "print(len(text))\n",
        "text_pd=pd.DataFrame(np.array(text))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CM9H1DI8vmq"
      },
      "source": [
        "def rem_fun(x):\n",
        "  split_string = x.split(\"\\n\", 1)\n",
        "  substring = split_string[0]\n",
        "  return substring[0]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AIw_sCA9v5O"
      },
      "source": [
        "text_pd_new=text_pd.replace(r'\\n',' ', regex=True).astype(str)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIV34qyH-41p"
      },
      "source": [
        "text_pd_new1=text_pd_new[0].str[:-1]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Siu-pQY_H6m"
      },
      "source": [
        "#text_pd_new1.to_csv('drive/MyDrive/kuba/text1.csv')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSCMbCO6Dt6W"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}